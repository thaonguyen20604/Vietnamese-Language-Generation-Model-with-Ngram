{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-RIoinBZiVU",
        "outputId": "913bd14d-ee71-4222-b6f9-d5699e4a8651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ƒê√£ x·ª≠ l√Ω 2378 ƒëo·∫°n vƒÉn v√† l∆∞u v√†o LS1_clean.txt\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def merge_lines(input_path, output_path):\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    paragraphs = []\n",
        "    current_para = \"\"\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue  # b·ªè d√≤ng tr·ªëng\n",
        "\n",
        "        if current_para:\n",
        "            # N·∫øu d√≤ng tr∆∞·ªõc k·∫øt th√∫c c√¢u v√† d√≤ng n√†y b·∫Øt ƒë·∫ßu ch·ªØ hoa -> xu·ªëng ƒëo·∫°n\n",
        "            if re.search(r\"[.!?]$\", current_para) and re.match(r\"^[A-Z√Ä-·ª∏]\", line):\n",
        "                paragraphs.append(current_para.strip())\n",
        "                current_para = line\n",
        "            else:\n",
        "                current_para += \" \" + line\n",
        "        else:\n",
        "            current_para = line\n",
        "\n",
        "    if current_para:\n",
        "        paragraphs.append(current_para.strip())\n",
        "\n",
        "    # Ghi ra file\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for p in paragraphs:\n",
        "            f.write(p + \"\\n\\n\")\n",
        "\n",
        "    print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω {len(paragraphs)} ƒëo·∫°n vƒÉn v√† l∆∞u v√†o {output_path}\")\n",
        "\n",
        "\n",
        "# Demo\n",
        "if __name__ == \"__main__\":\n",
        "    merge_lines(\"/content/LS1.txt\", \"LS1_clean.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwuHMMN3xfT1"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"tuannguyenvananh/vietnamese-plain-text-corpus\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "75W39zeMYPOC",
        "outputId": "1d2ad3cb-cdd2-4fef-e8ff-a1142ec5d4fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'vietnamese-plain-text-corpus' dataset.\n",
            "üìÇ Path to dataset files: /kaggle/input/vietnamese-plain-text-corpus\n",
            "‚úÖ ƒê·ªçc 42744 t√†i li·ªáu, 8 ch·ªß ƒë·ªÅ.\n",
            "\n",
            "üìö Th·ªëng k√™ theo ch·ªß ƒë·ªÅ:\n",
            "                  num_docs  avg_num_sentences_per_doc  total_sentences  \\\n",
            "topic                                                                    \n",
            "Phap luat             6656                      13.99            93086   \n",
            "Chinh tri Xa hoi      6567                      16.33           107270   \n",
            "The gioi              5716                      14.84            84839   \n",
            "The thao              5667                      23.97           135847   \n",
            "Van hoa               5250                      24.69           129629   \n",
            "Suc khoe              4417                      19.36            85535   \n",
            "Kinh doanh            4276                      16.63            71098   \n",
            "Doi song              4195                      28.96           121508   \n",
            "\n",
            "                  avg_sentence_length  \n",
            "topic                                  \n",
            "Phap luat                       33.35  \n",
            "Chinh tri Xa hoi                33.02  \n",
            "The gioi                        28.04  \n",
            "The thao                        27.59  \n",
            "Van hoa                         24.80  \n",
            "Suc khoe                        26.28  \n",
            "Kinh doanh                      32.35  \n",
            "Doi song                        23.55  \n",
            "\n",
            "üìä T·ªïng th·ªÉ:\n",
            "- T·ªïng s·ªë vƒÉn b·∫£n: 42744\n",
            "- T·ªïng s·ªë c√¢u: 828812\n",
            "- Trung b√¨nh s·ªë c√¢u / vƒÉn b·∫£n: 19.39\n",
            "- Trung b√¨nh ƒë·ªô d√†i c√¢u (s·ªë t·ª´): 28.98\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1Ô∏è‚É£ T·∫£i d·ªØ li·ªáu\n",
        "path = kagglehub.dataset_download(\"tuannguyenvananh/vietnamese-plain-text-corpus\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 2Ô∏è‚É£ H√†m ƒë·ªçc d·ªØ li·ªáu an to√†n\n",
        "def read_text_files(base_dir):\n",
        "    data = []\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(\".txt\"):\n",
        "                file_path = os.path.join(root, file)\n",
        "                topic = os.path.basename(root)\n",
        "                text = None\n",
        "                # Th·ª≠ nhi·ªÅu encoding kh√°c nhau\n",
        "                for enc in [\"utf-8\", \"utf-16\", \"utf-8-sig\", \"latin-1\"]:\n",
        "                    try:\n",
        "                        with open(file_path, \"r\", encoding=enc) as f:\n",
        "                            text = f.read().strip()\n",
        "                        break\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if text is None:\n",
        "                    print(f\"‚ö†Ô∏è B·ªè qua file l·ªói: {file_path}\")\n",
        "                    continue\n",
        "                data.append({\"topic\": topic, \"text\": text})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# 3Ô∏è‚É£ H√†m t√°ch c√¢u\n",
        "def split_sentences(text):\n",
        "    return re.split(r'(?<=[.!?])\\s+', text)\n",
        "\n",
        "# 4Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu\n",
        "df = read_text_files(path)\n",
        "print(f\"‚úÖ ƒê·ªçc {len(df)} t√†i li·ªáu, {df['topic'].nunique()} ch·ªß ƒë·ªÅ.\")\n",
        "\n",
        "# 5Ô∏è‚É£ T√≠nh th·ªëng k√™ chi ti·∫øt cho t·ª´ng vƒÉn b·∫£n\n",
        "df[\"sentences\"] = df[\"text\"].apply(lambda x: [s.strip() for s in split_sentences(x) if len(s.strip()) > 0])\n",
        "df[\"num_sentences\"] = df[\"sentences\"].apply(len)\n",
        "df[\"avg_sentence_len\"] = df[\"sentences\"].apply(lambda sents: sum(len(s.split()) for s in sents) / len(sents) if len(sents) > 0 else 0)\n",
        "\n",
        "# 6Ô∏è‚É£ T·ªïng h·ª£p th·ªëng k√™ theo ch·ªß ƒë·ªÅ\n",
        "topic_stats = df.groupby(\"topic\").agg({\n",
        "    \"num_sentences\": [\"count\", \"mean\", \"sum\"],\n",
        "    \"avg_sentence_len\": \"mean\"\n",
        "}).round(2)\n",
        "topic_stats.columns = [\"num_docs\", \"avg_num_sentences_per_doc\", \"total_sentences\", \"avg_sentence_length\"]\n",
        "topic_stats = topic_stats.sort_values(\"num_docs\", ascending=False)\n",
        "\n",
        "print(\"\\nüìö Th·ªëng k√™ theo ch·ªß ƒë·ªÅ:\")\n",
        "print(topic_stats)\n",
        "\n",
        "# 7Ô∏è‚É£ Th·ªëng k√™ to√†n t·∫≠p\n",
        "total_sentences = df[\"num_sentences\"].sum()\n",
        "avg_sent_per_doc = df[\"num_sentences\"].mean()\n",
        "avg_sent_len = df[\"avg_sentence_len\"].mean()\n",
        "print(\"\\nüìä T·ªïng th·ªÉ:\")\n",
        "print(f\"- T·ªïng s·ªë vƒÉn b·∫£n: {len(df)}\")\n",
        "print(f\"- T·ªïng s·ªë c√¢u: {total_sentences}\")\n",
        "print(f\"- Trung b√¨nh s·ªë c√¢u / vƒÉn b·∫£n: {avg_sent_per_doc:.2f}\")\n",
        "print(f\"- Trung b√¨nh ƒë·ªô d√†i c√¢u (s·ªë t·ª´): {avg_sent_len:.2f}\")\n",
        "\n",
        "# 8Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(df[\"num_sentences\"], bins=50, edgecolor='black')\n",
        "plt.title(\"Ph√¢n b·ªë s·ªë c√¢u trong m·ªói vƒÉn b·∫£n\")\n",
        "plt.xlabel(\"S·ªë c√¢u trong vƒÉn b·∫£n\")\n",
        "plt.ylabel(\"S·ªë l∆∞·ª£ng vƒÉn b·∫£n\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "topic_stats[\"total_sentences\"].plot(kind=\"bar\")\n",
        "plt.title(\"T·ªïng s·ªë c√¢u theo t·ª´ng ch·ªß ƒë·ªÅ\")\n",
        "plt.xlabel(\"Ch·ªß ƒë·ªÅ\")\n",
        "plt.ylabel(\"S·ªë c√¢u\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtarhtX2gmke"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9b4903c9",
        "outputId": "b4f1ce59-a07a-4f13-b1ed-bf4cdd28a859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-8.3.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from underthesea) (8.3.0)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.12/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from underthesea) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from underthesea) (2.32.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.6.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from underthesea) (6.0.3)\n",
            "Collecting underthesea_core==1.0.5 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from underthesea) (0.35.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8->underthesea) (2024.11.6)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->underthesea) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->underthesea) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->underthesea) (2025.8.3)\n",
            "Downloading underthesea-8.3.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading underthesea_core-1.0.5-cp312-cp312-manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m978.4/978.4 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: underthesea_core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.11 underthesea-8.3.0 underthesea_core-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install underthesea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcuzLgXjC68v"
      },
      "source": [
        "# 8/10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TZBT_HET0oc"
      },
      "source": [
        "### n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9NdT0oNOEik",
        "outputId": "ad863bd2-8a73-4875-aea9-82eb2394698f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ƒêang x√¢y d·ª±ng vocabulary t·ª´ t·∫≠p train...\n",
            "Vocabulary g·ªìm 90,041 token (sau khi l·ªçc t·∫ßn su·∫•t >= 2).\n",
            "Vocab ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o /content/vocab3.txt\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# ==== 6. X√¢y d·ª±ng vocab ====\n",
        "def build_vocab(train_text_path, min_freq=2):\n",
        "    \"\"\"\n",
        "    X√¢y d·ª±ng vocabulary t·ª´ t·∫≠p train.\n",
        "    - train_text_path: ƒë∆∞·ªùng d·∫´n ƒë·∫øn file train.txt\n",
        "    - min_freq: ng∆∞·ª°ng t·∫ßn su·∫•t t·ªëi thi·ªÉu ƒë·ªÉ gi·ªØ token\n",
        "    \"\"\"\n",
        "    print(\"\\nƒêang x√¢y d·ª±ng vocabulary t·ª´ t·∫≠p train...\")\n",
        "\n",
        "    with open(train_text_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # T√°ch token (c√°c t·ª´ ƒë√£ c√≥ s·∫µn kho·∫£ng tr·∫Øng)\n",
        "    tokens = text.split()\n",
        "\n",
        "    # ƒê·∫øm t·∫ßn su·∫•t xu·∫•t hi·ªán\n",
        "    counter = Counter(tokens)\n",
        "\n",
        "    # Gi·ªØ l·∫°i token c√≥ t·∫ßn su·∫•t >= min_freq\n",
        "    vocab = [tok for tok, freq in counter.items() if freq >= min_freq]\n",
        "\n",
        "    # Th√™m c√°c token ƒë·∫∑c bi·ªát\n",
        "    special_tokens = [\"<unk>\", \"<s>\", \"</s>\", \"<start_doc>\", \"<end_doc>\"]\n",
        "    for t in special_tokens:\n",
        "        if t not in vocab:\n",
        "            vocab.insert(0, t)\n",
        "\n",
        "    print(f\"Vocabulary g·ªìm {len(vocab):,} token (sau khi l·ªçc t·∫ßn su·∫•t >= {min_freq}).\")\n",
        "\n",
        "    # L∆∞u vocab ra file\n",
        "    vocab_path = \"/content/vocab3.txt\"\n",
        "    with open(vocab_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for tok in vocab:\n",
        "            f.write(tok + \"\\n\")\n",
        "\n",
        "    print(f\"Vocab ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o {vocab_path}\")\n",
        "    return vocab\n",
        "\n",
        "# G·ªçi h√†m x√¢y vocab\n",
        "vocab = build_vocab(\"/content/train (3).txt\", min_freq=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjJesgzeO4pt"
      },
      "source": [
        "## n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-pwWE7bchZ1",
        "outputId": "d0ba9123-7563-4ce1-facf-b2d86be132f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒê·ªçc 1 d√≤ng train.\n"
          ]
        }
      ],
      "source": [
        "# ==== 1. ƒê·ªçc vocab ====\n",
        "with open(\"/content/vocab2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = [line.strip() for line in f if line.strip()]\n",
        "vocab_set = set(vocab)\n",
        "\n",
        "UNK = \"<unk>\"\n",
        "START = \"<s>\"\n",
        "END = \"</s>\"\n",
        "START_DOC = \"<start_doc>\"\n",
        "END_DOC = \"<end_doc>\"\n",
        "\n",
        "\n",
        "# ==== 2. ƒê·ªçc d·ªØ li·ªáu hu·∫•n luy·ªán ====\n",
        "def read_corpus(path):\n",
        "    corpus = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            tokens = line.split()\n",
        "            # Thay t·ª´ ngo√†i vocab b·∫±ng <unk>\n",
        "            tokens = [t if t in vocab_set else UNK for t in tokens]\n",
        "            corpus.append(tokens)\n",
        "    return corpus\n",
        "\n",
        "\n",
        "train_data = read_corpus(\"/content/train (2).txt\")\n",
        "print(f\"ƒê·ªçc {len(train_data)} d√≤ng train.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJAnglGRO5xh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "class NgramModel:\n",
        "    def __init__(self, n, vocab):\n",
        "        self.n = n\n",
        "        # lo·∫°i b·ªè <unk> kh·ªèi vocab khi sinh\n",
        "        self.vocab = [w for w in vocab if w not in {\"<unk>\", \"<UNK>\"}]\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.context_counts = Counter()\n",
        "\n",
        "    def train(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence) - self.n + 1):\n",
        "                ngram = tuple(sentence[i:i+self.n])\n",
        "                context = ngram[:-1]\n",
        "                token = ngram[-1]\n",
        "                self.ngram_counts[context][token] += 1\n",
        "                self.context_counts[context] += 1\n",
        "        print(f\"Hu·∫•n luy·ªán xong m√¥ h√¨nh {self.n}-gram.\")\n",
        "\n",
        "    def prob(self, context, word, alpha=0.1, epsilon=0.05):\n",
        "        \"\"\"Add-Œ± smoothing + label smoothing nh·∫π.\"\"\"\n",
        "        context = tuple(context)\n",
        "        numerator = self.ngram_counts[context][word] + alpha\n",
        "        denominator = self.context_counts[context] + alpha * len(self.vocab)\n",
        "        p = numerator / denominator\n",
        "        # label smoothing\n",
        "        p = (1 - epsilon) * p + epsilon / len(self.vocab)\n",
        "        return p\n",
        "\n",
        "    def generate(self, start_text=\"\", max_len=256, max_sentences=3,\n",
        "                 temperature=0.8, mode=\"sample\"):\n",
        "        \"\"\"\n",
        "        Sinh vƒÉn b·∫£n v·ªõi sampling c√≥ nhi·ªát ƒë·ªô.\n",
        "        mode='greedy' -> ch·ªçn x√°c su·∫•t cao nh·∫•t\n",
        "        mode='sample' -> ch·ªçn ng·∫´u nhi√™n theo ph√¢n ph·ªëi\n",
        "        \"\"\"\n",
        "        if start_text.strip() == \"\":\n",
        "            sentence = [START]\n",
        "        else:\n",
        "            tokens = start_text.strip().split()\n",
        "            tokens = [t if t in self.vocab else \"<unk>\" for t in tokens]\n",
        "            sentence = [START] + tokens\n",
        "\n",
        "        sentence_count = 0\n",
        "        while len(sentence) < max_len:\n",
        "            context = sentence[-(self.n - 1):]\n",
        "            probs = [(w, self.prob(context, w)) for w in self.vocab]\n",
        "            words, p = zip(*probs)\n",
        "\n",
        "            if mode == \"greedy\":\n",
        "                next_word = words[p.index(max(p))]\n",
        "            else:\n",
        "                # temperature sampling\n",
        "                adjusted = [pi ** (1 / temperature) for pi in p]\n",
        "                next_word = random.choices(words, weights=adjusted, k=1)[0]\n",
        "\n",
        "            if next_word in {\"<end_doc>\", END_DOC}:\n",
        "                break\n",
        "\n",
        "            sentence.append(next_word)\n",
        "\n",
        "            if next_word in {\"</s>\", END}:\n",
        "                sentence_count += 1\n",
        "                if sentence_count >= max_sentences:\n",
        "                    break\n",
        "\n",
        "        return \" \".join(sentence[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJZWgDYAcieR",
        "outputId": "c090d255-0aac-4ec8-8876-c004c9971605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 3-gram.\n"
          ]
        }
      ],
      "source": [
        "n = 3\n",
        "model = NgramModel(n, vocab)\n",
        "model.train(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwWE9j2VdAOV",
        "outputId": "190663de-e003-4360-ffa1-40da3e5300a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "VƒÉn b·∫£n sinh ra:\n",
            "k·∫ø_ho·∫°ch ƒë∆∞a_ƒë√≥n mi·ªÖn_ph√≠ h√†nh_kh√°ch t·ª´ vn ( evn ) . </s> <s> theo √¥ng , vi·ªác x√¢y_d·ª±ng c√°c c√¥ng_tr√¨nh x√¢y_d·ª±ng . </s> <s> theo √¥ng , vi·ªác x√¢y_d·ª±ng c√°c c√¥ng_tr√¨nh x√¢y_d·ª±ng . </s>\n"
          ]
        }
      ],
      "source": [
        "# ==== 5. Sinh vƒÉn b·∫£n ====\n",
        "prompt = \"k·∫ø_ho·∫°ch ƒë∆∞a_ƒë√≥n mi·ªÖn_ph√≠\"\n",
        "generated = model.generate(prompt, mode = \"greedy\")\n",
        "print(\"\\nVƒÉn b·∫£n sinh ra:\")\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL6TiBgbsj8j"
      },
      "source": [
        "# c√≥ context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE0dyd6SrxSD",
        "outputId": "26485202-c746-425b-e572-4a68956a4495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 5-gram v·ªõi 23692 t·ª´ v·ª±ng.\n"
          ]
        }
      ],
      "source": [
        "model = NgramModel(n=5)\n",
        "model.train(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cpdgAqrquui",
        "outputId": "b3d7ccb1-6abb-4281-8fdb-8793946bcd56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K·∫øt qu·∫£ sinh:\n",
            "<s> vi·ªác x√°c_ƒë·ªãnh c√°c tuy·∫øn ƒë∆∞·ªùng . </s> <s> theo √¥ng <unk> , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc\n"
          ]
        }
      ],
      "source": [
        "context = \"<s> vi·ªác x√°c_ƒë·ªãnh c√°c tuy·∫øn\"\n",
        "output = model.generate(start_text=context,  max_len=128, temperature=0.8, mode=\"greedy\")\n",
        "\n",
        "print(\"K·∫øt qu·∫£ sinh:\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChLc1pU5t3m-",
        "outputId": "41354dd5-a03b-46a3-a51b-32066d999a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K·∫øt qu·∫£ sinh:\n",
            "d·ª±_ki·∫øn , c·ª© 15 ph√∫t l·∫°i c√≥ m·ªôt c∆°n l·ªëc xo√°y , nh∆∞ng tr√™n th·ª±c_t·∫ø , nhi·ªÅu tr∆∞·ªùng v·∫´n \" v∆∞·ª£t_r√†o \" , ti·∫øp_nh·∫≠n h·ªì_s∆° t·ª´ nhi·ªÅu ng√†y_tr∆∞·ªõc v√† nh·∫≠n c·∫£ nh·ªØng h·ªì_s∆° n·ªôp tr·ª±c_ti·∫øp . </s> <s> c√°c t·ªânh ven bi·ªÉn t·ª´ qu·∫£ng_ninh ƒë·∫øn thanh_h√≥a . </s> <s> do ·∫£nh_h∆∞·ªüng c·ªßa b√£o , khu_v·ª±c b·∫Øc bi·ªÉn ƒë√¥ng c√≥ gi√≥ xo√°y m·∫°nh c·∫•p 7 ƒë·∫øn thanh_h√≥a . </s> <s> do ·∫£nh_h∆∞·ªüng c·ªßa b√£o , khu_v·ª±c b·∫Øc bi·ªÉn ƒë√¥ng c√≥ gi√≥ xo√°y m·∫°nh c·∫•p 7 , c·∫•p 8 , v√πng g·∫ßn t√¢m_b√£o c·∫•p 11-12 , gi·∫≠t tr√™n c·∫•p 10 . bi·ªÉn ƒë·ªông r·∫•t m·∫°nh . </s> <s> c√°c t·ªânh ven bi·ªÉn t·ª´ qu·∫£ng_ninh ƒë·∫øn thanh_h√≥a . </s> <s> do ·∫£nh_h∆∞·ªüng c·ªßa b√£o , khu_v·ª±c b·∫Øc bi·ªÉn ƒë√¥ng c√≥ gi√≥ ven bi·ªÉn t·ª´ qu·∫£ng_ninh ƒë·∫øn thanh_h√≥a . </s> <s> do ·∫£nh_h∆∞·ªüng c·ªßa b√£o , khu_v·ª±c b·∫Øc bi·ªÉn ƒë√¥ng c√≥ gi√≥ xo√°y m·∫°nh c·∫•p 7 , c·∫•p 8 , v√πng g·∫ßn t√¢m_b√£o c·∫•p 11-12 , gi·∫≠t tr√™n c·∫•p 10 . bi·ªÉn ƒë·ªông r·∫•t m·∫°nh . </s> <s> c√°c t·ªânh ven bi·ªÉn t·ª´ qu·∫£ng_ninh ƒë·∫øn thanh_h√≥a . </s> <s> do ·∫£nh_h∆∞·ªüng c·ªßa b√£o , khu_v·ª±c b·∫Øc\n"
          ]
        }
      ],
      "source": [
        "# Sinh ti·∫øp vƒÉn b·∫£n t·ª´ context cho s·∫µn\n",
        "context = \"d·ª±_ki·∫øn , c·ª© 15 ph√∫t\"\n",
        "output = model.generate_paragraph(start_text=context, num_sentences=3, n_context=len(context), temperature=0.8, mode=\"greedy\")\n",
        "\n",
        "print(\"K·∫øt qu·∫£ sinh:\")\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EShb0HJhwjVZ"
      },
      "outputs": [],
      "source": [
        "test_data = read_corpus(\"/content/test (1).txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QbhZcch-QQm",
        "outputId": "f5e90f62-3425-48fd-8599-4a0093ce3e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 2-gram v·ªõi 23692 t·ª´ v·ª±ng.\n"
          ]
        }
      ],
      "source": [
        "model = NgramModel(n=2)\n",
        "model.train(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so50aN8qyHK8",
        "outputId": "fc41b0a2-cc68-4002-f6a0-27cb47f45852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S·ªë context ch∆∞a t·ª´ng th·∫•y: 0\n",
            "T·ªïng context test: 292792\n",
            "T·ªâ l·ªá unseen context: 0.00%\n",
            "X√°c su·∫•t trung b√¨nh: 0.05869150\n"
          ]
        }
      ],
      "source": [
        "from statistics import mean\n",
        "\n",
        "contexts_with_zero = []\n",
        "probs = []\n",
        "\n",
        "for sent in test_data:\n",
        "    for i in range(model.n - 1, len(sent)):\n",
        "        ctx = tuple(sent[i - model.n + 1:i])\n",
        "        w = sent[i]\n",
        "        p = model.prob(ctx, w)\n",
        "        probs.append(p)\n",
        "        if model.context_counts[ctx] == 0:\n",
        "            contexts_with_zero.append(ctx)\n",
        "\n",
        "print(f\"S·ªë context ch∆∞a t·ª´ng th·∫•y: {len(contexts_with_zero)}\")\n",
        "print(f\"T·ªïng context test: {len(probs)}\")\n",
        "print(f\"T·ªâ l·ªá unseen context: {len(contexts_with_zero) / len(probs) * 100:.2f}%\")\n",
        "print(f\"X√°c su·∫•t trung b√¨nh: {mean(probs):.8f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQSRZDTGzLOt",
        "outputId": "6f9bc4a7-7bd4-424c-ccf7-420a544fde16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total tokens counted: 271895\n",
            "Mean p (arithmetic): 0.0062554031271840884\n",
            "Mean ln(p): -7.06676441256822\n",
            "Mean log2(p): -10.195185973143577\n",
            "Perplexity (nats / exp(-mean_ln)): 1172.3486543791714\n",
            "Perplexity (bits / 2^{-mean_log2}): 1172.3486543798194\n",
            "Min p: 3.359537727608681e-06\n",
            "Median p: 0.0008835584223610831\n",
            "Frac p < 1e-6: 0.0\n",
            "Frac p < 1e-3: 0.5189687195424705\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from statistics import mean\n",
        "\n",
        "def compute_diagnostics(model, test_data, ignore_tokens=None):\n",
        "    if ignore_tokens is None:\n",
        "        ignore_tokens = {\"<start_doc>\", \"<end_doc>\", \"<s>\", \"</s>\"}\n",
        "\n",
        "    total_log_e = 0.0       # sum ln p\n",
        "    total_log2 = 0.0        # sum log2 p\n",
        "    total_tokens = 0\n",
        "    probs = []\n",
        "\n",
        "    for sent in test_data:\n",
        "        for i in range(model.n - 1, len(sent)):\n",
        "            w = sent[i]\n",
        "            ctx = sent[i - model.n + 1:i]\n",
        "            if w in ignore_tokens:\n",
        "                continue\n",
        "            p = model.prob(tuple(ctx), w)\n",
        "            probs.append(p)\n",
        "            total_log_e += math.log(p + 1e-12)\n",
        "            total_log2 += math.log2(p + 1e-12)\n",
        "            total_tokens += 1\n",
        "\n",
        "    mean_ln = total_log_e / total_tokens\n",
        "    mean_log2 = total_log2 / total_tokens\n",
        "\n",
        "    ppl_nats = math.exp(-mean_ln)         # perplexity using natural log\n",
        "    ppl_bits = 2 ** (-mean_log2)          # perplexity using log2\n",
        "\n",
        "    print(\"Total tokens counted:\", total_tokens)\n",
        "    print(\"Mean p (arithmetic):\", mean(probs))\n",
        "    print(\"Mean ln(p):\", mean_ln)\n",
        "    print(\"Mean log2(p):\", mean_log2)\n",
        "    print(\"Perplexity (nats / exp(-mean_ln)):\", ppl_nats)\n",
        "    print(\"Perplexity (bits / 2^{-mean_log2}):\", ppl_bits)\n",
        "\n",
        "    # extra diagnostics\n",
        "    probs_sorted = sorted(probs)\n",
        "    print(\"Min p:\", probs_sorted[0])\n",
        "    print(\"Median p:\", probs_sorted[len(probs)//2])\n",
        "    print(\"Frac p < 1e-6:\", sum(1 for x in probs if x < 1e-6)/len(probs))\n",
        "    print(\"Frac p < 1e-3:\", sum(1 for x in probs if x < 1e-3)/len(probs))\n",
        "    return {\n",
        "        \"total_tokens\": total_tokens,\n",
        "        \"mean_p\": mean(probs),\n",
        "        \"ppl_nats\": ppl_nats,\n",
        "        \"ppl_bits\": ppl_bits\n",
        "    }\n",
        "\n",
        "# g·ªçi:\n",
        "diagnostics = compute_diagnostics(model, test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sL3yx-dO6Q5"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt73fYBuXJWf",
        "outputId": "b5b10f20-8653-45a4-ba1b-2dd4913cc960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Vocab size: 23692\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# ƒê·ªçc vocab\n",
        "with open(\"/content/vocab2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx2word = {i: w for i, w in enumerate(vocab)}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocab size: {vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdRFjU6sXpD2"
      },
      "outputs": [],
      "source": [
        "def encode_text(text, word2idx, unk_token=\"<unk>\"):\n",
        "    tokens = text.strip().split()\n",
        "    return [word2idx.get(t, word2idx[unk_token]) for t in tokens]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVvkTeJ-ZEaW",
        "outputId": "f84b26c7-db94-43d9-f200-1913d3e5acba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S·ªë l∆∞·ª£ng token trong train: 2,367,821\n"
          ]
        }
      ],
      "source": [
        "# ƒê·ªçc d·ªØ li·ªáu ƒë√£ tokenized\n",
        "with open(\"/content/train (2).txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_text = f.read()\n",
        "\n",
        "train_ids = encode_text(train_text, word2idx)\n",
        "print(f\"S·ªë l∆∞·ª£ng token trong train: {len(train_ids):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Znh-imvW1sF"
      },
      "source": [
        "## n-gram 11/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe0Sf-nmd0VT"
      },
      "outputs": [],
      "source": [
        "UNK = \"<unk>\"\n",
        "START = \"<s>\"\n",
        "END = \"</s>\"\n",
        "START_DOC = \"<start_doc>\"\n",
        "END_DOC = \"<end_doc>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrg7n374W3Vx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "\n",
        "\n",
        "class NgramModel:\n",
        "    def __init__(self, n, vocab, discount=0.75):\n",
        "        self.n = n\n",
        "        self.vocab = [w for w in vocab if w not in {\"<unk>\", \"<UNK>\"}]\n",
        "        self.discount = discount\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.context_counts = Counter()\n",
        "        self.lower_order = None\n",
        "\n",
        "    def train(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence) - self.n + 1):\n",
        "                ngram = tuple(sentence[i:i+self.n])\n",
        "                context = ngram[:-1]\n",
        "                token = ngram[-1]\n",
        "                self.ngram_counts[context][token] += 1\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "        if self.n > 1:\n",
        "            self.lower_order = NgramModel(self.n - 1, self.vocab, self.discount)\n",
        "            self.lower_order.train(corpus)\n",
        "\n",
        "        print(f\"Hu·∫•n luy·ªán xong m√¥ h√¨nh {self.n}-gram (Kneser‚ÄìNey) v·ªõi {len(self.vocab)} t·ª´.\")\n",
        "\n",
        "    def continuation_prob(self, word):\n",
        "        contexts_with_word = sum(1 for ctx in self.ngram_counts if word in self.ngram_counts[ctx])\n",
        "        total_contexts = len(self.ngram_counts)\n",
        "        return contexts_with_word / total_contexts if total_contexts > 0 else 1e-8\n",
        "\n",
        "    def prob(self, context, word):\n",
        "        context = tuple(context)\n",
        "        count_context = self.context_counts[context]\n",
        "        count_ngram = self.ngram_counts[context][word]\n",
        "\n",
        "        if self.n == 1:\n",
        "            return self.continuation_prob(word)\n",
        "\n",
        "        if count_context > 0:\n",
        "            p_cont = self.lower_order.prob(context[1:], word)\n",
        "            unique_followers = len(self.ngram_counts[context])\n",
        "            prob = max(count_ngram - self.discount, 0) / count_context\n",
        "            prob += (self.discount * unique_followers / count_context) * p_cont\n",
        "        else:\n",
        "            prob = self.lower_order.prob(context[1:], word)\n",
        "\n",
        "        return prob\n",
        "\n",
        "    def perplexity(self, corpus):\n",
        "        N = 0\n",
        "        log_prob_sum = 0\n",
        "        for sentence in corpus:\n",
        "            for i in range(self.n - 1, len(sentence)):\n",
        "                context = tuple(sentence[i - self.n + 1:i])\n",
        "                word = sentence[i]\n",
        "                p = self.prob(context, word)\n",
        "                log_prob_sum += -math.log(p + 1e-12)\n",
        "                N += 1\n",
        "        return math.exp(log_prob_sum / N)\n",
        "\n",
        "    def generate(self, start_text=\"\", max_len=200, max_sentences=4, temperature=0.8, mode=\"sample\"):\n",
        "        \"\"\"Sinh vƒÉn b·∫£n b·∫±ng Kneser‚ÄìNey.\"\"\"\n",
        "        if start_text.strip() == \"\":\n",
        "            sentence = [START]\n",
        "        else:\n",
        "            tokens = start_text.strip().split()\n",
        "            tokens = [t if t in self.vocab else \"<unk>\" for t in tokens]\n",
        "            sentence = [START] + tokens\n",
        "\n",
        "        sentence_count = 0\n",
        "        while len(sentence) < max_len:\n",
        "            context = sentence[-(self.n - 1):]\n",
        "            probs = [self.prob(context, w) for w in self.vocab]\n",
        "            words = self.vocab\n",
        "\n",
        "            if mode == \"greedy\":\n",
        "                next_word = words[int(np.argmax(probs))]\n",
        "                p_next = max(probs)\n",
        "            else:\n",
        "                adjusted = np.array(probs) ** (1 / temperature)\n",
        "                adjusted /= np.sum(adjusted)\n",
        "                next_word = random.choices(words, weights=adjusted, k=1)[0]\n",
        "                p_next = self.prob(context, next_word)\n",
        "\n",
        "            print(f\"p({next_word} | {' '.join(context)}) = {p_next:.6f}\")\n",
        "\n",
        "            if next_word == END:\n",
        "                sentence_count += 1\n",
        "                if (sentence_count >= max_sentences) or (next_word == END_DOC) :\n",
        "                    break\n",
        "                sentence.append(END)\n",
        "                sentence.append(START)\n",
        "                continue\n",
        "\n",
        "            sentence.append(next_word)\n",
        "\n",
        "        return \" \".join(sentence[1:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObKEeGZSOeYN"
      },
      "outputs": [],
      "source": [
        "def read_corpus(path):\n",
        "    corpus = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            tokens = line.strip().split()\n",
        "            if not tokens:\n",
        "                continue\n",
        "            sentence = []\n",
        "            for tok in tokens:\n",
        "                if tok == START:\n",
        "                    sentence = [START]\n",
        "                elif tok == END:\n",
        "                    sentence.append(END)\n",
        "                    corpus.append(sentence)\n",
        "                    sentence = []\n",
        "                else:\n",
        "                    sentence.append(tok)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB-XUk-IW5TO",
        "outputId": "96628c91-b651-4c00-9c8a-5d826492bc58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 1-gram (Kneser‚ÄìNey) v·ªõi 90040 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 2-gram (Kneser‚ÄìNey) v·ªõi 90040 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 3-gram (Kneser‚ÄìNey) v·ªõi 90040 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 4-gram (Kneser‚ÄìNey) v·ªõi 90040 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 5-gram (Kneser‚ÄìNey) v·ªõi 90040 t·ª´.\n",
            "Perplexity train: 6.452547029896682\n",
            "Perplexity test: 10.225737224827082\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = NgramModel(n=5, vocab=vocab, discount=1)\n",
        "model.train(train_corpus)\n",
        "\n",
        "print(\"Perplexity train:\", model.perplexity(train_corpus))\n",
        "print(\"Perplexity test:\", model.perplexity(test_corpus))\n",
        "\n",
        "\n",
        "# # B∆∞·ªõc 3: Hu·∫•n luy·ªán\n",
        "# n = 4\n",
        "# model = NgramModel(n=n, vocab=vocab)\n",
        "# model.train(train_corpus)\n",
        "\n",
        "# # B∆∞·ªõc 4: ƒê√°nh gi√°\n",
        "# ppl_train = model.perplexity(train_corpus)\n",
        "# ppl_test = model.perplexity(test_corpus)\n",
        "# print(f\"Perplexity train: {ppl_train:.2f}\")\n",
        "# print(f\"Perplexity test: {ppl_test:.2f}\")\n",
        "\n",
        "# alphas = [0.05, 0.1, 0.2, 0.5, 1.0]\n",
        "# for a in alphas:\n",
        "#     ppl_train = model.perplexity(train_corpus, alpha=a)\n",
        "#     ppl_test = model.perplexity(test_corpus, alpha=a)\n",
        "#     print(f\"alpha={a}: ppl_train={ppl_train:.2f}, ppl_test={ppl_test:.2f}\")\n",
        "\n",
        "# # B∆∞·ªõc 5: Sinh vƒÉn b·∫£n\n",
        "# start = \"tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa\"\n",
        "# print(\"\\nSinh vƒÉn b·∫£n:\")\n",
        "# output = model.generate(start_text=start, mode=\"greedy\", temperature=0.8)\n",
        "# print(f\"Input: {start}\\nOutput: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVVauHo32S_H",
        "outputId": "180c777e-92d5-445f-d055-0c30d2a92307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OOV rate: 0.008881292534086484\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "def oov_rate(train_corpus, test_corpus):\n",
        "    vocab = set(w for s in train_corpus for w in s)\n",
        "    total = 0\n",
        "    oov = 0\n",
        "    for s in test_corpus:\n",
        "        for w in s:\n",
        "            total += 1\n",
        "            if w not in vocab:\n",
        "                oov += 1\n",
        "    return oov/total\n",
        "print(\"OOV rate:\", oov_rate(train_corpus, test_corpus))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MfXqwrsbbC8t",
        "outputId": "41b77a4b-8c09-4955-8cb1-4a7c0e437062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sinh vƒÉn b·∫£n:\n",
            "p(. | qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa) = 0.273200\n",
            "p(</s> | nh√† ƒë·ªÉ gi·∫£i_t·ªèa .) = 0.999755\n",
            "p(- | gi·∫£i_t·ªèa . </s> <s>) = 0.070647\n",
            "p(t√¥i | . </s> <s> -) = 0.119180\n",
            "p(kh√¥ng | </s> <s> - t√¥i) = 0.157870\n",
            "p(c√≥ | <s> - t√¥i kh√¥ng) = 0.143088\n",
            "p(√Ω_ƒë·ªãnh | - t√¥i kh√¥ng c√≥) = 0.295726\n",
            "p(tr·ªü_th√†nh | t√¥i kh√¥ng c√≥ √Ω_ƒë·ªãnh) = 0.217206\n",
            "p(m·ªôt | kh√¥ng c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh) = 0.646600\n",
            "p(di·ªÖn_vi√™n | c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt) = 0.170681\n",
            "p(chuy√™n_nghi·ªáp | √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n) = 0.619046\n",
            "p(? | tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp) = 0.437604\n",
            "p(</s> | m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp ?) = 0.998261\n",
            "p(- | chuy√™n_nghi·ªáp ? </s> <s>) = 0.070647\n",
            "p(t√¥i | ? </s> <s> -) = 0.119180\n",
            "p(kh√¥ng | </s> <s> - t√¥i) = 0.157870\n",
            "p(c√≥ | <s> - t√¥i kh√¥ng) = 0.143088\n",
            "p(√Ω_ƒë·ªãnh | - t√¥i kh√¥ng c√≥) = 0.295726\n",
            "p(tr·ªü_th√†nh | t√¥i kh√¥ng c√≥ √Ω_ƒë·ªãnh) = 0.217206\n",
            "p(m·ªôt | kh√¥ng c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh) = 0.646600\n",
            "p(di·ªÖn_vi√™n | c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt) = 0.170681\n",
            "p(chuy√™n_nghi·ªáp | √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n) = 0.619046\n",
            "p(? | tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp) = 0.437604\n",
            "p(</s> | m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp ?) = 0.998261\n",
            "p(- | chuy√™n_nghi·ªáp ? </s> <s>) = 0.070647\n",
            "p(t√¥i | ? </s> <s> -) = 0.119180\n",
            "p(kh√¥ng | </s> <s> - t√¥i) = 0.157870\n",
            "p(c√≥ | <s> - t√¥i kh√¥ng) = 0.143088\n",
            "p(√Ω_ƒë·ªãnh | - t√¥i kh√¥ng c√≥) = 0.295726\n",
            "p(tr·ªü_th√†nh | t√¥i kh√¥ng c√≥ √Ω_ƒë·ªãnh) = 0.217206\n",
            "p(m·ªôt | kh√¥ng c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh) = 0.646600\n",
            "p(di·ªÖn_vi√™n | c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt) = 0.170681\n",
            "p(chuy√™n_nghi·ªáp | √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n) = 0.619046\n",
            "p(? | tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp) = 0.437604\n",
            "p(</s> | m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp ?) = 0.998261\n",
            "Input: <start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa\n",
            "Output: <start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa . </s> <s> - t√¥i kh√¥ng c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp ? </s> <s> - t√¥i kh√¥ng c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp ? </s> <s> - t√¥i kh√¥ng c√≥ √Ω_ƒë·ªãnh tr·ªü_th√†nh m·ªôt di·ªÖn_vi√™n chuy√™n_nghi·ªáp ?\n"
          ]
        }
      ],
      "source": [
        "start = \"<start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa\"\n",
        "\n",
        "\n",
        "# print(\"\\n=== Sinh vƒÉn b·∫£n ===\")\n",
        "# print(model.generate(start_text=start, max_len=200, max_sentences=4, temperature=0.8, mode=\"greedy\"))\n",
        "\n",
        "\n",
        "print(\"\\nSinh vƒÉn b·∫£n:\")\n",
        "output = model.generate(start_text=start, max_sentences=4, temperature=0.8, mode=\"greedy\")\n",
        "print(f\"Input: {start}\\nOutput: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KSZ2cvS-n96",
        "outputId": "968c4e2c-702c-46a6-a1e8-8eeb6b1a002a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 90041\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "\n",
            "Interpolation (Œª=[0.5, 0.3, 0.2]): Test PPL = 3.30\n",
            "\n",
            "===== SINH VƒÇN B·∫¢N =====\n",
            "Greedy:\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'prob'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2913864776.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Greedy:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"greedy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSampling:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2913864776.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, start_text, max_len, temperature, mode)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2913864776.py\u001b[0m in \u001b[0;36mprob\u001b[0;34m(self, context, word)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munique_followers\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcount_context\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_cont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'prob'"
          ]
        }
      ],
      "source": [
        "import math, random\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "START = \"<s>\"\n",
        "END = \"</s>\"\n",
        "\n",
        "# ======================\n",
        "# ƒê·ªçc d·ªØ li·ªáu\n",
        "# ======================\n",
        "def read_corpus(path):\n",
        "    corpus = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            tokens = line.strip().split()\n",
        "            if not tokens:\n",
        "                continue\n",
        "            sentence = []\n",
        "            for tok in tokens:\n",
        "                if tok == START:\n",
        "                    sentence = [START]\n",
        "                elif tok == END:\n",
        "                    sentence.append(END)\n",
        "                    corpus.append(sentence)\n",
        "                    sentence = []\n",
        "                else:\n",
        "                    sentence.append(tok)\n",
        "    return corpus\n",
        "\n",
        "\n",
        "# ======================\n",
        "# M√¥ h√¨nh Kneser‚ÄìNey\n",
        "# ======================\n",
        "class NgramModel:\n",
        "    def __init__(self, n, vocab, discount=0.75):\n",
        "        self.n = n\n",
        "        self.vocab = vocab\n",
        "        self.discount = discount\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.context_counts = Counter()\n",
        "        self.lower_order = None\n",
        "\n",
        "    def train(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence) - self.n + 1):\n",
        "                ngram = tuple(sentence[i:i+self.n])\n",
        "                context = ngram[:-1]\n",
        "                token = ngram[-1]\n",
        "                self.ngram_counts[context][token] += 1\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "        # hu·∫•n luy·ªán lower order\n",
        "        if self.n > 1:\n",
        "            self.lower_order = NgramModel(self.n - 1, self.vocab, self.discount)\n",
        "            self.lower_order.train(corpus)\n",
        "\n",
        "        print(f\"Hu·∫•n luy·ªán xong {self.n}-gram (Kneser‚ÄìNey) v·ªõi {len(self.vocab)} t·ª´.\")\n",
        "\n",
        "    def continuation_prob(self, word):\n",
        "        contexts_with_word = sum(1 for ctx in self.ngram_counts if word in self.ngram_counts[ctx])\n",
        "        total_contexts = len(self.ngram_counts)\n",
        "        return contexts_with_word / total_contexts if total_contexts > 0 else 1e-8\n",
        "\n",
        "    def prob(self, context, word):\n",
        "        context = tuple(context)\n",
        "        count_context = self.context_counts[context]\n",
        "        count_ngram = self.ngram_counts[context][word]\n",
        "\n",
        "        if self.n == 1:\n",
        "            return self.continuation_prob(word)\n",
        "\n",
        "        if count_context > 0:\n",
        "            p_cont = self.lower_order.prob(context[1:], word)\n",
        "            unique_followers = len(self.ngram_counts[context])\n",
        "            prob = max(count_ngram - self.discount, 0) / count_context\n",
        "            prob += (self.discount * unique_followers / count_context) * p_cont\n",
        "        else:\n",
        "            prob = self.lower_order.prob(context[1:], word)\n",
        "\n",
        "        return prob\n",
        "\n",
        "    def perplexity(self, corpus):\n",
        "        N = 0\n",
        "        log_prob_sum = 0\n",
        "        for sentence in corpus:\n",
        "            for i in range(self.n - 1, len(sentence)):\n",
        "                context = tuple(sentence[i - self.n + 1:i])\n",
        "                word = sentence[i]\n",
        "                p = self.prob(context, word)\n",
        "                log_prob_sum += -math.log(p + 1e-12)\n",
        "                N += 1\n",
        "        return math.exp(log_prob_sum / N)\n",
        "\n",
        "    def generate(self, start_text=\"\", max_len=120, temperature=0.8, mode=\"sample\"):\n",
        "        if not start_text.strip():\n",
        "            sentence = [START]\n",
        "        else:\n",
        "            tokens = start_text.strip().split()\n",
        "            sentence = [START] + [t if t in self.vocab else \"<unk>\" for t in tokens]\n",
        "\n",
        "        while len(sentence) < max_len:\n",
        "            context = sentence[-(self.n - 1):]\n",
        "            probs = [self.prob(context, w) for w in self.vocab]\n",
        "            words = self.vocab\n",
        "\n",
        "            if mode == \"greedy\":\n",
        "                next_word = words[probs.index(max(probs))]\n",
        "            else:\n",
        "                adjusted = [p ** (1 / temperature) for p in probs]\n",
        "                total = sum(adjusted)\n",
        "                adjusted = [p / total for p in adjusted]\n",
        "                next_word = random.choices(words, weights=adjusted, k=1)[0]\n",
        "\n",
        "            print(f\"[CTX: {' '.join(context)}] ‚Üí {next_word} (p={max(probs):.6f})\")\n",
        "            if next_word == END:\n",
        "                break\n",
        "            sentence.append(next_word)\n",
        "\n",
        "        return \" \".join(sentence[1:])\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Pruning\n",
        "# ======================\n",
        "def prune_counts(model, min_count=2):\n",
        "    new_ngram = defaultdict(Counter)\n",
        "    new_context = Counter()\n",
        "    for ctx, counter in model.ngram_counts.items():\n",
        "        for w, c in counter.items():\n",
        "            if c >= min_count:\n",
        "                new_ngram[ctx][w] = c\n",
        "                new_context[ctx] += c\n",
        "    model.ngram_counts = new_ngram\n",
        "    model.context_counts = new_context\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Linear interpolation\n",
        "# ======================\n",
        "def interp_prob(models, context, word, lambdas):\n",
        "    p = 0.0\n",
        "    for m, lam in zip(models, lambdas):\n",
        "        ctx_len = m.n - 1\n",
        "        ctx = context[-ctx_len:] if ctx_len > 0 else []\n",
        "        p += lam * m.prob(ctx, word)\n",
        "    return p\n",
        "\n",
        "def interp_perplexity(models, corpus, lambdas):\n",
        "    N = 0\n",
        "    log_prob_sum = 0\n",
        "    for sentence in corpus:\n",
        "        for i in range(max(m.n for m in models) - 1, len(sentence)):\n",
        "            context = sentence[i - models[0].n + 1:i]\n",
        "            word = sentence[i]\n",
        "            p = interp_prob(models, context, word, lambdas)\n",
        "            log_prob_sum += -math.log(p + 1e-12)\n",
        "            N += 1\n",
        "    return math.exp(log_prob_sum / N)\n",
        "\n",
        "\n",
        "# ======================\n",
        "# TH·ª∞C NGHI·ªÜM\n",
        "# ======================\n",
        "train_path = \"/content/train (3).txt\"\n",
        "test_path = \"/content/test (2).txt\"\n",
        "\n",
        "train_corpus = read_corpus(train_path)\n",
        "test_corpus = read_corpus(test_path)\n",
        "# vocab = list({w for sent in train_corpus for w in sent})\n",
        "import torch\n",
        "\n",
        "# ƒê·ªçc vocab\n",
        "with open(\"/content/vocab3.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx2word = {i: w for i, w in enumerate(vocab)}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocab size: {vocab_size}\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# for n in [3, 4, 5]:\n",
        "#     for D in [0.5, 0.75, 1.0]:\n",
        "#         model = NgramModel(n, vocab, discount=D)\n",
        "#         model.train(train_corpus)\n",
        "#         ppl_train = model.perplexity(train_corpus)\n",
        "#         ppl_test = model.perplexity(test_corpus)\n",
        "#         results.append((n, D, ppl_train, ppl_test))\n",
        "\n",
        "# print(\"\\n===== B·∫¢NG SO S√ÅNH PERPLEXITY =====\")\n",
        "# print(\"n\\tDiscount\\tTrain PPL\\tTest PPL\")\n",
        "# for n, D, tr, te in results:\n",
        "#     print(f\"{n}\\t{D:.2f}\\t\\t{tr:.2f}\\t\\t{te:.2f}\")\n",
        "\n",
        "# Th·ª≠ pruning cho m√¥ h√¨nh t·ªët nh·∫•t\n",
        "# # best_n, best_D, _, _ = min(results, key=lambda x: x[3])\n",
        "best_model = NgramModel(5, vocab, discount=1)\n",
        "# best_model.train(train_corpus)\n",
        "# prune_counts(best_model, min_count=2)\n",
        "# print(f\"\\nSau pruning (n={5}, D={1}): Test PPL = {best_model.perplexity(test_corpus):.2f}\")\n",
        "\n",
        "# Linear interpolation (3+4+5)\n",
        "models = []\n",
        "for n in [3, 4]:\n",
        "    m = NgramModel(n, vocab, discount=0.75)\n",
        "    m.train(train_corpus)\n",
        "    models.append(m)\n",
        "lambdas = [0.5, 0.3, 0.2]\n",
        "interp_ppl = interp_perplexity(models, test_corpus, lambdas)\n",
        "print(f\"\\nInterpolation (Œª={lambdas}): Test PPL = {interp_ppl:.2f}\")\n",
        "\n",
        "# Sinh th·ª≠ vƒÉn b·∫£n\n",
        "print(\"\\n===== SINH VƒÇN B·∫¢N =====\")\n",
        "prompt = \"<start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa\"\n",
        "print(\"Greedy:\")\n",
        "print(best_model.generate(prompt, mode=\"greedy\"))\n",
        "print(\"\\nSampling:\")\n",
        "print(best_model.generate(prompt, mode=\"sample\", temperature=0.8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E-Tbic7jn7zP"
      },
      "outputs": [],
      "source": [
        "import math, random, pickle\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "START = \"<s>\"\n",
        "END = \"</s>\"\n",
        "\n",
        "# ======================\n",
        "# ƒê·ªçc d·ªØ li·ªáu\n",
        "# ======================\n",
        "def read_corpus(path):\n",
        "    corpus = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            tokens = line.strip().split()\n",
        "            if not tokens:\n",
        "                continue\n",
        "            sentence = []\n",
        "            for tok in tokens:\n",
        "                if tok == START:\n",
        "                    sentence = [START]\n",
        "                elif tok == END:\n",
        "                    sentence.append(END)\n",
        "                    corpus.append(sentence)\n",
        "                    sentence = []\n",
        "                else:\n",
        "                    sentence.append(tok)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krga1_KaoHve",
        "outputId": "87fe67a6-2449-4324-eb96-722dd7316e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 90041\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# TH·ª∞C NGHI·ªÜM\n",
        "# ======================\n",
        "train_path = \"/content/train (3).txt\"\n",
        "test_path = \"/content/test (2).txt\"\n",
        "\n",
        "train_corpus = read_corpus(train_path)\n",
        "test_corpus = read_corpus(test_path)\n",
        "\n",
        "import torch\n",
        "\n",
        "# ƒê·ªçc vocab\n",
        "with open(\"/content/vocab3.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx2word = {i: w for i, w in enumerate(vocab)}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocab size: {vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ixIO2tb2PPgD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ======================\n",
        "# M√¥ h√¨nh Kneser‚ÄìNey\n",
        "# ======================\n",
        "class NgramModel:\n",
        "    def __init__(self, n, vocab, discount=0.75):\n",
        "        self.n = n\n",
        "        self.vocab = vocab\n",
        "        self.discount = discount\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.context_counts = Counter()\n",
        "        self.lower_order = None\n",
        "\n",
        "    def train(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence) - self.n + 1):\n",
        "                ngram = tuple(sentence[i:i+self.n])\n",
        "                context = ngram[:-1]\n",
        "                token = ngram[-1]\n",
        "                self.ngram_counts[context][token] += 1\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "        # hu·∫•n luy·ªán lower order\n",
        "        if self.n > 1:\n",
        "            self.lower_order = NgramModel(self.n - 1, self.vocab, self.discount)\n",
        "            self.lower_order.train(corpus)\n",
        "\n",
        "        print(f\"Hu·∫•n luy·ªán xong {self.n}-gram (Kneser‚ÄìNey) v·ªõi {len(self.vocab)} t·ª´.\")\n",
        "\n",
        "    def continuation_prob(self, word):\n",
        "        contexts_with_word = sum(1 for ctx in self.ngram_counts if word in self.ngram_counts[ctx])\n",
        "        total_contexts = len(self.ngram_counts)\n",
        "        return contexts_with_word / total_contexts if total_contexts > 0 else 1e-8\n",
        "\n",
        "    def prob(self, context, word):\n",
        "        context = tuple(context)\n",
        "        count_context = self.context_counts[context]\n",
        "        count_ngram = self.ngram_counts[context][word]\n",
        "\n",
        "        if self.n == 1:\n",
        "            return self.continuation_prob(word)\n",
        "\n",
        "        if count_context > 0:\n",
        "            p_cont = self.lower_order.prob(context[1:], word)\n",
        "            unique_followers = len(self.ngram_counts[context])\n",
        "            prob = max(count_ngram - self.discount, 0) / count_context\n",
        "            prob += (self.discount * unique_followers / count_context) * p_cont\n",
        "        else:\n",
        "            prob = self.lower_order.prob(context[1:], word)\n",
        "\n",
        "        return prob\n",
        "\n",
        "    def perplexity(self, corpus):\n",
        "        N = 0\n",
        "        log_prob_sum = 0\n",
        "        for sentence in corpus:\n",
        "            for i in range(self.n - 1, len(sentence)):\n",
        "                context = tuple(sentence[i - self.n + 1:i])\n",
        "                word = sentence[i]\n",
        "                p = self.prob(context, word)\n",
        "                log_prob_sum += -math.log(p + 1e-12)\n",
        "                N += 1\n",
        "        return math.exp(log_prob_sum / N)\n",
        "\n",
        "    def generate(self, start_text=\"\", max_len=120, temperature=0.8, mode=\"sample\"):\n",
        "        if not start_text.strip():\n",
        "            sentence = [START]\n",
        "        else:\n",
        "            tokens = start_text.strip().split()\n",
        "            sentence = [START] + [t if t in self.vocab else \"<unk>\" for t in tokens]\n",
        "\n",
        "        while len(sentence) < max_len:\n",
        "            context = sentence[-(self.n - 1):]\n",
        "            probs = [self.prob(context, w) for w in self.vocab]\n",
        "            words = self.vocab\n",
        "\n",
        "            if mode == \"greedy\":\n",
        "                next_word = words[probs.index(max(probs))]\n",
        "            else:\n",
        "                adjusted = [p ** (1 / temperature) for p in probs]\n",
        "                total = sum(adjusted)\n",
        "                adjusted = [p / total for p in adjusted]\n",
        "                next_word = random.choices(words, weights=adjusted, k=1)[0]\n",
        "\n",
        "            print(f\"[CTX: {' '.join(context)}] ‚Üí {next_word} (p={max(probs):.6f})\")\n",
        "            if next_word == END:\n",
        "                break\n",
        "            sentence.append(next_word)\n",
        "\n",
        "        return \" \".join(sentence[1:])\n",
        "\n",
        "def save_model(model, path):\n",
        "    \"\"\"L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (k·ªÉ c·∫£ lower_order)\"\"\"\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"ƒê√£ l∆∞u m√¥ h√¨nh v√†o: {path}\")\n",
        "\n",
        "def load_model(path):\n",
        "    \"\"\"T·∫£i l·∫°i m√¥ h√¨nh\"\"\"\n",
        "    with open(path, \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "    print(f\"ƒê√£ t·∫£i m√¥ h√¨nh t·ª´: {path}\")\n",
        "    return model\n",
        "\n",
        "# ======================\n",
        "# Pruning\n",
        "# ======================\n",
        "def prune_counts(model, min_count=2):\n",
        "    new_ngram = defaultdict(Counter)\n",
        "    new_context = Counter()\n",
        "    for ctx, counter in model.ngram_counts.items():\n",
        "        for w, c in counter.items():\n",
        "            if c >= min_count:\n",
        "                new_ngram[ctx][w] = c\n",
        "                new_context[ctx] += c\n",
        "    model.ngram_counts = new_ngram\n",
        "    model.context_counts = new_context\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Linear interpolation\n",
        "# ======================\n",
        "def interp_prob(models, context, word, lambdas):\n",
        "    p = 0.0\n",
        "    for m, lam in zip(models, lambdas):\n",
        "        ctx_len = m.n - 1\n",
        "        ctx = context[-ctx_len:] if ctx_len > 0 else []\n",
        "        p += lam * m.prob(ctx, word)\n",
        "    return p\n",
        "\n",
        "def interp_perplexity(models, corpus, lambdas):\n",
        "    N = 0\n",
        "    log_prob_sum = 0\n",
        "    for sentence in corpus:\n",
        "        for i in range(max(m.n for m in models) - 1, len(sentence)):\n",
        "            context = sentence[i - models[0].n + 1:i]\n",
        "            word = sentence[i]\n",
        "            p = interp_prob(models, context, word, lambdas)\n",
        "            log_prob_sum += -math.log(p + 1e-12)\n",
        "            N += 1\n",
        "    return math.exp(log_prob_sum / N)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nEZmttyECYcW",
        "outputId": "05ffddaf-5981-499f-9beb-fd01587aed55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "\n",
            "===== B·∫¢NG SO S√ÅNH PERPLEXITY =====\n",
            "n\tDiscount\tTrain PPL\tTest PPL\n",
            "3\t0.50\t\t5.84\t\t14.33\n",
            "3\t0.75\t\t4.96\t\t9.17\n",
            "3\t1.00\t\t4.28\t\t6.52\n",
            "4\t0.50\t\t2.34\t\t15.41\n",
            "4\t0.75\t\t2.88\t\t9.39\n",
            "4\t1.00\t\t4.04\t\t6.54\n",
            "5\t0.50\t\t1.44\t\t15.60\n",
            "5\t0.75\t\t1.92\t\t9.30\n",
            "5\t1.00\t\t3.94\t\t6.50\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 23692 t·ª´.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'pickle' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3502661990.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"/content/ngram_{best_n}gram_D{best_D}.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2106835368.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, path)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m\"\"\"L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (k·ªÉ c·∫£ lower_order)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ƒê√£ l∆∞u m√¥ h√¨nh v√†o: {path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ],
      "source": [
        "#data nh·ªè\n",
        "\n",
        "# results = []\n",
        "\n",
        "# for n in [3, 4, 5]:\n",
        "#     for D in [0.5, 0.75, 1.0]:\n",
        "#         model = NgramModel(n, vocab, discount=D)\n",
        "#         model.train(train_corpus)\n",
        "#         ppl_train = model.perplexity(train_corpus)\n",
        "#         ppl_test = model.perplexity(test_corpus)\n",
        "#         results.append((n, D, ppl_train, ppl_test))\n",
        "\n",
        "# print(\"\\n===== B·∫¢NG SO S√ÅNH PERPLEXITY =====\")\n",
        "# print(\"n\\tDiscount\\tTrain PPL\\tTest PPL\")\n",
        "# for n, D, tr, te in results:\n",
        "#     print(f\"{n}\\t{D:.2f}\\t\\t{tr:.2f}\\t\\t{te:.2f}\")\n",
        "\n",
        "# Th·ª≠ pruning cho m√¥ h√¨nh t·ªët nh·∫•t\n",
        "best_n, best_D, _, _ = min(results, key=lambda x: x[3])\n",
        "best_model = NgramModel(best_n, vocab, discount=best_D)\n",
        "best_model.train(train_corpus)\n",
        "\n",
        "save_model(best_model, f\"/content/ngram_{best_n}gram_D{best_D}.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-zZ475qoKOv",
        "outputId": "b0bf7c73-5512-449d-9044-6ecb53ad6adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "\n",
            "===== B·∫¢NG SO S√ÅNH PERPLEXITY =====\n",
            "n\tDiscount\tTrain PPL\tTest PPL\n",
            "3\t0.50\t\t10.40\t\t20.87\n",
            "3\t0.75\t\t8.72\t\t14.05\n",
            "3\t1.00\t\t7.57\t\t10.32\n",
            "4\t0.50\t\t3.38\t\t22.43\n",
            "4\t0.75\t\t4.23\t\t14.22\n",
            "4\t1.00\t\t6.80\t\t10.27\n",
            "5\t0.50\t\t1.67\t\t23.08\n",
            "5\t0.75\t\t2.32\t\t14.08\n",
            "5\t1.00\t\t6.45\t\t10.23\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for n in [3, 4, 5]:\n",
        "    for D in [0.5, 0.75, 1.0]:\n",
        "        model = NgramModel(n, vocab, discount=D)\n",
        "        model.train(train_corpus)\n",
        "        ppl_train = model.perplexity(train_corpus)\n",
        "        ppl_test = model.perplexity(test_corpus)\n",
        "        results.append((n, D, ppl_train, ppl_test))\n",
        "\n",
        "print(\"\\n===== B·∫¢NG SO S√ÅNH PERPLEXITY =====\")\n",
        "print(\"n\\tDiscount\\tTrain PPL\\tTest PPL\")\n",
        "for n, D, tr, te in results:\n",
        "    print(f\"{n}\\t{D:.2f}\\t\\t{tr:.2f}\\t\\t{te:.2f}\")\n",
        "\n",
        "# Th·ª≠ pruning cho m√¥ h√¨nh t·ªët nh·∫•t\n",
        "best_n, best_D, _, _ = min(results, key=lambda x: x[3])\n",
        "best_model = NgramModel(best_n, vocab, discount=best_D)\n",
        "best_model.train(train_corpus)\n",
        "\n",
        "save_model(best_model, f\"/content/ngram_{best_n}gram_D{best_D}.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DVdg6q53o7g",
        "outputId": "0540e6b2-87d3-41ec-c5d4-9c98dfa1f317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 1-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 2-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 3-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 4-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n",
            "Hu·∫•n luy·ªán xong 5-gram (Kneser‚ÄìNey) v·ªõi 90041 t·ª´.\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for n in [3, 4, 5]:\n",
        "    for D in [0.5, 0.75, 1.0]:\n",
        "        model = NgramModel(n, vocab, discount=D)\n",
        "        model.train(train_corpus)\n",
        "        ppl_train = model.perplexity(train_corpus)\n",
        "        ppl_test = model.perplexity(test_corpus)\n",
        "        results.append((n, D, ppl_train, ppl_test))\n",
        "\n",
        "# print(\"\\n===== B·∫¢NG SO S√ÅNH PERPLEXITY =====\")\n",
        "# print(\"n\\tDiscount\\tTrain PPL\\tTest PPL\")\n",
        "# for n, D, tr, te in results:\n",
        "#     print(f\"{n}\\t{D:.2f}\\t\\t{tr:.2f}\\t\\t{te:.2f}\")\n",
        "\n",
        "# Th·ª≠ pruning cho m√¥ h√¨nh t·ªët nh·∫•t\n",
        "best_n, best_D, _, _ = min(results, key=lambda x: x[3])\n",
        "best_model = NgramModel(best_n, vocab, discount=best_D)\n",
        "best_model.train(train_corpus)\n",
        "\n",
        "save_model(best_model, f\"/content/ngram_{best_n}gram_D{best_D}.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61_GG5xA2bz9"
      },
      "source": [
        "# 12/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a8146a89",
        "outputId": "c721d03b-3eb5-47c5-ca80-983c62ad6182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_ZwMJ0WKQFe",
        "outputId": "251806d8-ec1d-436b-ba9a-3ed0e64a4908"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o_34GXhD2c9T"
      },
      "outputs": [],
      "source": [
        "UNK = \"<unk>\"\n",
        "START = \"<s>\"\n",
        "END = \"</s>\"\n",
        "START_DOC = \"<start_doc>\"\n",
        "END_DOC = \"<end_doc>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HSCwcN8M2gN8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "\n",
        "\n",
        "class NgramModel:\n",
        "    def __init__(self, n, vocab, discount=0.75):\n",
        "        self.n = n\n",
        "        self.vocab = [w for w in vocab if w not in {\"<unk>\", \"<UNK>\"}]\n",
        "        self.discount = discount\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.context_counts = Counter()\n",
        "        self.lower_order = None\n",
        "\n",
        "    def train(self, corpus):\n",
        "        for sentence in corpus:\n",
        "            for i in range(len(sentence) - self.n + 1):\n",
        "                ngram = tuple(sentence[i:i+self.n])\n",
        "                context = ngram[:-1]\n",
        "                token = ngram[-1]\n",
        "                self.ngram_counts[context][token] += 1\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "        if self.n > 1:\n",
        "            self.lower_order = NgramModel(self.n - 1, self.vocab, self.discount)\n",
        "            self.lower_order.train(corpus)\n",
        "\n",
        "        print(f\"Hu·∫•n luy·ªán xong m√¥ h√¨nh {self.n}-gram (Kneser‚ÄìNey) v·ªõi {len(self.vocab)} t·ª´.\")\n",
        "\n",
        "    def continuation_prob(self, word):\n",
        "        contexts_with_word = sum(1 for ctx in self.ngram_counts if word in self.ngram_counts[ctx])\n",
        "        total_contexts = len(self.ngram_counts)\n",
        "        return contexts_with_word / total_contexts if total_contexts > 0 else 1e-8\n",
        "\n",
        "    def prob(self, context, word):\n",
        "        context = tuple(context)\n",
        "        count_context = self.context_counts[context]\n",
        "        count_ngram = self.ngram_counts[context][word]\n",
        "\n",
        "        if self.n == 1:\n",
        "            return self.continuation_prob(word)\n",
        "\n",
        "        if count_context > 0:\n",
        "            p_cont = self.lower_order.prob(context[1:], word)\n",
        "            unique_followers = len(self.ngram_counts[context])\n",
        "            prob = max(count_ngram - self.discount, 0) / count_context\n",
        "            prob += (self.discount * unique_followers / count_context) * p_cont\n",
        "        else:\n",
        "            prob = self.lower_order.prob(context[1:], word)\n",
        "\n",
        "        return prob\n",
        "\n",
        "    def perplexity(self, corpus):\n",
        "        N = 0\n",
        "        log_prob_sum = 0\n",
        "        for sentence in corpus:\n",
        "            for i in range(self.n - 1, len(sentence)):\n",
        "                context = tuple(sentence[i - self.n + 1:i])\n",
        "                word = sentence[i]\n",
        "                p = self.prob(context, word)\n",
        "                log_prob_sum += -math.log(p + 1e-12)\n",
        "                N += 1\n",
        "        return math.exp(log_prob_sum / N)\n",
        "\n",
        "    def generate(self, start_text=\"\", max_len=200, max_sentences=4, temperature=0.8, mode=\"sample\"):\n",
        "        \"\"\"Sinh vƒÉn b·∫£n b·∫±ng Kneser‚ÄìNey.\"\"\"\n",
        "        if start_text.strip() == \"\":\n",
        "            sentence = [START]\n",
        "        else:\n",
        "            tokens = start_text.strip().split()\n",
        "            tokens = [t if t in self.vocab else \"<unk>\" for t in tokens]\n",
        "            sentence = [START] + tokens\n",
        "\n",
        "        sentence_count = 0\n",
        "        while len(sentence) < max_len:\n",
        "            context = sentence[-(self.n - 1):]\n",
        "            probs = [self.prob(context, w) for w in self.vocab]\n",
        "            words = self.vocab\n",
        "\n",
        "            if mode == \"greedy\":\n",
        "                next_word = words[int(np.argmax(probs))]\n",
        "                p_next = max(probs)\n",
        "            else:\n",
        "                adjusted = np.array(probs) ** (1 / temperature)\n",
        "                adjusted /= np.sum(adjusted)\n",
        "                next_word = random.choices(words, weights=adjusted, k=1)[0]\n",
        "                p_next = self.prob(context, next_word)\n",
        "\n",
        "            # print(f\"p({next_word} | {' '.join(context)}) = {p_next:.6f}\")\n",
        "\n",
        "            if next_word == END:\n",
        "                sentence_count += 1\n",
        "                if (sentence_count >= max_sentences) or (next_word == END_DOC) :\n",
        "                    break\n",
        "                sentence.append(END)\n",
        "                sentence.append(START)\n",
        "                continue\n",
        "\n",
        "            sentence.append(next_word)\n",
        "\n",
        "        return \" \".join(sentence[1:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "87oUEBE92jz0"
      },
      "outputs": [],
      "source": [
        "def read_corpus(path):\n",
        "    corpus = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            tokens = line.strip().split()\n",
        "            if not tokens:\n",
        "                continue\n",
        "            sentence = []\n",
        "            for tok in tokens:\n",
        "                if tok == START:\n",
        "                    sentence = [START]\n",
        "                elif tok == END:\n",
        "                    sentence.append(END)\n",
        "                    corpus.append(sentence)\n",
        "                    sentence = []\n",
        "                else:\n",
        "                    sentence.append(tok)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1RitUt42mXP",
        "outputId": "d8150c29-4cb4-473d-f01a-c947475a275e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 23692\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# train_path = \"/content/train (3).txt\"\n",
        "# test_path = \"/content/test (2).txt\"\n",
        "\n",
        "train_path = \"/content/train (2).txt\"\n",
        "test_path = \"/content/test (1).txt\"\n",
        "\n",
        "train_corpus = read_corpus(train_path)\n",
        "test_corpus = read_corpus(test_path)\n",
        "\n",
        "import torch\n",
        "\n",
        "with open(\"/content/vocab2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx2word = {i: w for i, w in enumerate(vocab)}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocab size: {vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voEsFMwA9mgh",
        "outputId": "ec58c73a-5ca9-414c-8be4-d47dace9aae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S·ªë c√¢u trong t·∫≠p train: 79103\n",
            "S·ªë token trong t·∫≠p train: 2357183\n",
            "S·ªë c√¢u trong t·∫≠p test: 9792\n",
            "S·ªë token trong t·∫≠p test: 291479\n"
          ]
        }
      ],
      "source": [
        "train_tokens = sum(len(s) for s in train_corpus)\n",
        "test_tokens = sum(len(s) for s in test_corpus)\n",
        "\n",
        "print(\"S·ªë c√¢u trong t·∫≠p train:\", len(train_corpus))\n",
        "print(\"S·ªë token trong t·∫≠p train:\", train_tokens)\n",
        "print(\"S·ªë c√¢u trong t·∫≠p test:\", len(test_corpus))\n",
        "print(\"S·ªë token trong t·∫≠p test:\", test_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlz2llxz2uOH",
        "outputId": "78c76155-a4ee-4c8f-95fb-1f83a2a5b3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 1-gram (Kneser‚ÄìNey) v·ªõi 23691 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 2-gram (Kneser‚ÄìNey) v·ªõi 23691 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 3-gram (Kneser‚ÄìNey) v·ªõi 23691 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 4-gram (Kneser‚ÄìNey) v·ªõi 23691 t·ª´.\n",
            "Hu·∫•n luy·ªán xong m√¥ h√¨nh 5-gram (Kneser‚ÄìNey) v·ªõi 23691 t·ª´.\n",
            "Perplexity train: 3.9365894572386737\n",
            "Perplexity test: 6.504108967288241\n"
          ]
        }
      ],
      "source": [
        "model = NgramModel(n=5, vocab=vocab, discount=1)\n",
        "model.train(train_corpus)\n",
        "\n",
        "print(\"Perplexity train:\", model.perplexity(train_corpus))\n",
        "print(\"Perplexity test:\", model.perplexity(test_corpus))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OmTjKeGI21NE",
        "outputId": "b157a977-51b5-449a-8acb-0422043eae03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sinh vƒÉn b·∫£n:\n",
            "Input: <start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa\n",
            "Output: <start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa m·∫∑t_b·∫±ng , kh√¥ng c√≥ s·ª± ph·ªëi_h·ª£p gi·ªØa c√°c ng√†nh , c√°c c·∫•p , c√°c ng√†nh c·∫ßn c√≥ s·ª± ph·ªëi_h·ª£p ch·∫∑t_ch·∫Ω v·ªõi c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , cao_ƒë·∫≥ng , trung_h·ªçc_chuy√™n_nghi·ªáp . </s> <s> theo √¥ng , c·∫ßn c√≥ s·ª± ph·ªëi_h·ª£p ch·∫∑t_ch·∫Ω v·ªõi c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , cao_ƒë·∫≥ng , trung_h·ªçc_chuy√™n_nghi·ªáp . </s> <s> theo √¥ng , c·∫ßn c√≥ s·ª± ph·ªëi_h·ª£p ch·∫∑t_ch·∫Ω v·ªõi c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , cao_ƒë·∫≥ng , trung_h·ªçc_chuy√™n_nghi·ªáp . </s> <s> theo √¥ng , c·∫ßn c√≥ s·ª± ph·ªëi_h·ª£p ch·∫∑t_ch·∫Ω v·ªõi c√°c tr∆∞·ªùng ƒë·∫°i_h·ªçc , cao_ƒë·∫≥ng , trung_h·ªçc_chuy√™n_nghi·ªáp .\n"
          ]
        }
      ],
      "source": [
        "start = \"<start_doc> <s> tp hcm t√¨m qu·ªπ nh√† ƒë·ªÉ gi·∫£i_t·ªèa\"\n",
        "\n",
        "\n",
        "# print(\"\\n=== Sinh vƒÉn b·∫£n ===\")\n",
        "# print(model.generate(start_text=start, max_len=200, max_sentences=4, temperature=0.8, mode=\"greedy\"))\n",
        "\n",
        "\n",
        "print(\"\\nSinh vƒÉn b·∫£n:\")\n",
        "output = model.generate(start_text=start, max_sentences=4, temperature=0.8, mode=\"greedy\")\n",
        "print(f\"Input: {start}\\nOutput: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhIuSZBJ6lLY"
      },
      "source": [
        "## ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng BLEU / ROUGE / METEOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "a8msKnou5yV2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def normalize_tokens(tokens):\n",
        "    \"\"\"Chu·∫©n h√≥a token ƒë·ªÉ ƒë√°nh gi√° BLEU / ROUGE / METEOR.\"\"\"\n",
        "    norm = []\n",
        "    for tok in tokens:\n",
        "        tok = tok.replace(\"_\", \" \")              # t√°ch l·∫°i t·ª´ gh√©p\n",
        "        tok = re.sub(r\"\\s+\", \" \", tok).strip()   # b·ªè th·ª´a kho·∫£ng tr·∫Øng\n",
        "        tok = re.sub(r\"([.,!?;:])\", r\" \\1 \", tok)  # t√°ch d·∫•u c√¢u\n",
        "        tok = tok.lower()\n",
        "        if tok:\n",
        "            norm.extend(tok.split())\n",
        "    return norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5Iq0BqnO6mFY"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "\n",
        "# ------------------ TI·ªÜN √çCH ------------------\n",
        "def extract_documents(corpus):\n",
        "    \"\"\"Gom c√°c c√¢u th√†nh 1 document duy nh·∫•t n·∫øu c·∫ßn.\"\"\"\n",
        "    docs = []\n",
        "    current_doc = []\n",
        "    for sent in corpus:\n",
        "        current_doc.extend(sent[1:-1])  # b·ªè <s> v√† </s>\n",
        "    if current_doc:\n",
        "        docs.append(current_doc)\n",
        "    return docs\n",
        "\n",
        "\n",
        "def normalize_tokens(tokens):\n",
        "    \"\"\"Chu·∫©n h√≥a token ƒë·ªÉ ƒë√°nh gi√° BLEU / ROUGE / METEOR.\"\"\"\n",
        "    norm = []\n",
        "    for tok in tokens:\n",
        "        tok = tok.replace(\"_\", \" \")              # t√°ch l·∫°i t·ª´ gh√©p ti·∫øng Vi·ªát\n",
        "        tok = re.sub(r\"\\s+\", \" \", tok).strip()   # b·ªè th·ª´a kho·∫£ng tr·∫Øng\n",
        "        tok = re.sub(r\"([.,!?;:])\", r\" \\1 \", tok)  # t√°ch d·∫•u c√¢u\n",
        "        tok = tok.lower()\n",
        "        if tok:\n",
        "            norm.extend(tok.split())\n",
        "    return norm\n",
        "\n",
        "\n",
        "# ------------------ H√ÄM ƒê√ÅNH GI√Å BLEU ------------------\n",
        "def evaluate_bleu(references, candidates):\n",
        "    if not references or not candidates:\n",
        "        return 0.0\n",
        "    smooth = SmoothingFunction().method4\n",
        "    bleu_score = corpus_bleu(references, candidates, smoothing_function=smooth)\n",
        "    return bleu_score\n",
        "\n",
        "\n",
        "# ------------------ H√ÄM ƒê√ÅNH GI√Å METEOR ------------------\n",
        "def evaluate_meteor(ref_list, gen_list):\n",
        "    scores = []\n",
        "    for ref_tokens, gen_tokens in zip(ref_list, gen_list):\n",
        "        try:\n",
        "            s = meteor_score([ref_tokens], gen_tokens)\n",
        "        except TypeError:\n",
        "            try:\n",
        "                s = meteor_score([\" \".join(ref_tokens)], \" \".join(gen_tokens))\n",
        "            except Exception:\n",
        "                s = 0.0\n",
        "        scores.append(s)\n",
        "    return np.mean(scores) if scores else 0.0\n",
        "\n",
        "\n",
        "# ------------------ H√ÄM ƒê√ÅNH GI√Å ROUGE ------------------\n",
        "def evaluate_rouge(ref_list, gen_list):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge1_scores, rougeL_scores = [], []\n",
        "    for ref_tokens, gen_tokens in zip(ref_list, gen_list):\n",
        "        try:\n",
        "            r = scorer.score(\" \".join(ref_tokens), \" \".join(gen_tokens))\n",
        "            rouge1_scores.append(r[\"rouge1\"].fmeasure)\n",
        "            rougeL_scores.append(r[\"rougeL\"].fmeasure)\n",
        "        except Exception:\n",
        "            rouge1_scores.append(0.0)\n",
        "            rougeL_scores.append(0.0)\n",
        "    avg_rouge1 = np.mean(rouge1_scores) if rouge1_scores else 0.0\n",
        "    avg_rougeL = np.mean(rougeL_scores) if rougeL_scores else 0.0\n",
        "    return avg_rouge1, avg_rougeL\n",
        "\n",
        "\n",
        "# ------------------ H√ÄM CH√çNH ------------------\n",
        "def evaluate_doc_level(model, test_corpus, max_sentences=3, num_samples=50,\n",
        "                       metrics=(\"BLEU\", \"METEOR\", \"ROUGE\"), mode=\"sample\"):\n",
        "    \"\"\"\n",
        "    ƒê√°nh gi√° m√¥ h√¨nh ·ªü m·ª©c t√†i li·ªáu.\n",
        "    metrics: tuple/list g·ªìm c√°c ch·ªâ s·ªë mu·ªën t√≠nh (\"BLEU\", \"METEOR\", \"ROUGE\").\n",
        "    \"\"\"\n",
        "    documents = extract_documents(test_corpus)\n",
        "    print(f\"C√≥ {len(documents)} t√†i li·ªáu trong t·∫≠p test.\")\n",
        "\n",
        "    references, candidates = [], []\n",
        "    ref_list_for_meteor, gen_list_for_meteor = [], []\n",
        "\n",
        "    sampled_docs = random.sample(documents, min(num_samples, len(documents)))\n",
        "\n",
        "    for doc in sampled_docs:\n",
        "        if len(doc) < 10:\n",
        "            continue\n",
        "        ref_tokens = [w for w in doc if w not in {\"<s>\", \"</s>\", \"<start_doc>\", \"<end_doc>\"}]\n",
        "        if not ref_tokens:\n",
        "            continue\n",
        "\n",
        "        prefix = \" \".join(ref_tokens[:6])\n",
        "        gen_text = model.generate(start_text=prefix, max_sentences=max_sentences, mode=mode)\n",
        "        gen_tokens = [w for w in gen_text.split() if w not in {\"<s>\", \"</s>\", \"<start_doc>\", \"<end_doc>\"}]\n",
        "\n",
        "        if len(gen_tokens) < 3:\n",
        "            continue\n",
        "\n",
        "        # üîπ Chu·∫©n h√≥a token ƒë·ªÉ ƒë√°nh gi√° ch√≠nh x√°c h∆°n\n",
        "        ref_tokens = normalize_tokens(ref_tokens)\n",
        "        gen_tokens = normalize_tokens(gen_tokens)\n",
        "\n",
        "        references.append([ref_tokens])\n",
        "        candidates.append(gen_tokens)\n",
        "        ref_list_for_meteor.append(ref_tokens)\n",
        "        gen_list_for_meteor.append(gen_tokens)\n",
        "\n",
        "    # ------------------ T√çNH CH·ªà S·ªê THEO Y√äU C·∫¶U ------------------\n",
        "    results = {}\n",
        "\n",
        "    if \"BLEU\" in metrics:\n",
        "        results[\"BLEU\"] = evaluate_bleu(references, candidates)\n",
        "        print(f\"BLEU-4 Score:  {results['BLEU']*100:.2f}\")\n",
        "\n",
        "    if \"METEOR\" in metrics:\n",
        "        results[\"METEOR\"] = evaluate_meteor(ref_list_for_meteor, gen_list_for_meteor)\n",
        "        print(f\"METEOR Score:  {results['METEOR']*100:.2f}\")\n",
        "\n",
        "    if \"ROUGE\" in metrics:\n",
        "        rouge1, rougeL = evaluate_rouge(ref_list_for_meteor, gen_list_for_meteor)\n",
        "        results[\"ROUGE-1\"] = rouge1\n",
        "        results[\"ROUGE-L\"] = rougeL\n",
        "        print(f\"ROUGE-1 F1:    {rouge1*100:.2f}\")\n",
        "        print(f\"ROUGE-L F1:    {rougeL*100:.2f}\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYMtzYtTr0Zq",
        "outputId": "e6ba8f77-7f49-4629-8cd7-d87d57ce8ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C√≥ 1 t√†i li·ªáu trong t·∫≠p test.\n",
            "BLEU-4 Score:  0.00\n"
          ]
        }
      ],
      "source": [
        "metrics_bleu = evaluate_doc_level(model, test_corpus, metrics=(\"BLEU\",), mode=\"greedy\")\n",
        "\n",
        "# N·∫øu mu·ªën t√≠nh c·∫£ BLEU + METEOR:\n",
        "# metrics_mix = evaluate_doc_level(model, test_corpus, metrics=(\"BLEU\", \"METEOR\"))\n",
        "\n",
        "# N·∫øu mu·ªën t√≠nh t·∫•t c·∫£ (nh∆∞ m·∫∑c ƒë·ªãnh):\n",
        "# metrics_all = evaluate_doc_level(model, test_corpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFWWsQhRwXXq",
        "outputId": "e72c1e7b-7c0a-42b8-e3d9-212e98e71fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C√≥ 1 t√†i li·ªáu trong t·∫≠p test.\n",
            "METEOR Score:  0.00\n"
          ]
        }
      ],
      "source": [
        "metrics_bleu = evaluate_doc_level(model, test_corpus, metrics=(\"METEOR\",), mode=\"greedy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx-5HIukx1o7",
        "outputId": "f42ea341-60b8-4c09-f1e2-cc658d245144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C√≥ 1 t√†i li·ªáu trong t·∫≠p test.\n"
          ]
        }
      ],
      "source": [
        "metrics_bleu = evaluate_doc_level(model, test_corpus, metrics=(\"ROUGE\",), mode=\"greedy\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
